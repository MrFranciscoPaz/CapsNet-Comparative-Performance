{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import os\n",
    "# listar el sistema de archivos\n",
    "import glob\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "#tf.random.set_seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x,y), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x432 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = x\n",
    "y_train = y\n",
    "plt.figure(figsize=(5, 6))\n",
    "for i in range(1, 10):\n",
    "    plt.subplot(330 + i)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(x_train[5 * i], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Train, x_Test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_Train[..., tf.newaxis]\n",
    "x_test = x_Test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.image.resize(x_train, size=[32,32])\n",
    "x_test = tf.image.resize(x_test, size=[32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 32, 32, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenet_1.00_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 33, 33, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 16, 16, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 4, 4, 256)         32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 4, 4, 256)         65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 2, 2, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 2, 2, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 1, 1, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 1, 1, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 1, 1, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 1, 1, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "=================================================================\n",
      "Total params: 3,228,288\n",
      "Trainable params: 3,206,400\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Se crea una instancia del modelo\n",
    "base_model = tf.keras.applications.MobileNet(weights= None, include_top=False, input_shape=(32,32,1))\n",
    "# se imprime la arquitectura del modelo\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation= 'relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(10, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 33, 33, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 16, 16, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 16, 16, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 16, 16, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 8, 8, 64)          576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 8, 8, 128)         8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 8, 8, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 8, 8, 128)         16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 4, 4, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 4, 4, 256)         32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 4, 4, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 4, 4, 256)         65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 2, 2, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 2, 2, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 2, 2, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 2, 2, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 1, 1, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 1, 1, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 1, 1, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 1, 1, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 1, 1, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,758,218\n",
      "Trainable params: 3,736,330\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1129 11:17:15.737787 14472 deprecation.py:323] From C:\\Users\\Francisco\\AppData\\Local\\Continuum\\anaconda3\\envs\\clasep3.6\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 116s 2ms/sample - loss: 0.4510 - accuracy: 0.8623\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 115s 2ms/sample - loss: 0.1572 - accuracy: 0.9602\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 115s 2ms/sample - loss: 0.1298 - accuracy: 0.9683 - loss: 0.1298 - accura\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.1118 - accuracy: 0.9737\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 110s 2ms/sample - loss: 0.0932 - accuracy: 0.9786\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 110s 2ms/sample - loss: 0.0912 - accuracy: 0.9796\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 110s 2ms/sample - loss: 0.0714 - accuracy: 0.9835\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.0621 - accuracy: 0.9857 - loss: 0.0620 - accuracy: 0.\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.0725 - accuracy: 0.9844 - loss: 0.0725 - accuracy: 0.98\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 111s 2ms/sample - loss: 0.0609 - accuracy: 0.9862\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.0427 - accuracy: 0.9900\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0497 - accuracy: 0.9884\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.0364 - accuracy: 0.9909\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0330 - accuracy: 0.9921\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0353 - accuracy: 0.9918\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.0365 - accuracy: 0.9919\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0270 - accuracy: 0.9935\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0538 - accuracy: 0.9901\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0259 - accuracy: 0.9938\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0201 - accuracy: 0.9949\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0240 - accuracy: 0.9944\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0237 - accuracy: 0.9944\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0224 - accuracy: 0.9950\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0238 - accuracy: 0.9942\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0184 - accuracy: 0.9955\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0201 - accuracy: 0.9950\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0166 - accuracy: 0.9958\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0177 - accuracy: 0.9960\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0294 - accuracy: 0.9944\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0172 - accuracy: 0.9959\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0176 - accuracy: 0.9959\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0187 - accuracy: 0.9959\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0166 - accuracy: 0.9963\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0121 - accuracy: 0.9970\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0152 - accuracy: 0.9966\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0128 - accuracy: 0.9971\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0135 - accuracy: 0.9968\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.0148 - accuracy: 0.9967\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0145 - accuracy: 0.9966\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0125 - accuracy: 0.9971\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 114s 2ms/sample - loss: 0.0125 - accuracy: 0.9973 - loss: 0 - ETA: 0s - loss: 0.0125 - \n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 115s 2ms/sample - loss: 0.0104 - accuracy: 0.9976\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 112s 2ms/sample - loss: 0.0116 - accuracy: 0.9976\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 115s 2ms/sample - loss: 0.0104 - accuracy: 0.9975\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 115s 2ms/sample - loss: 0.0219 - accuracy: 0.9964\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 223s 4ms/sample - loss: 0.0170 - accuracy: 0.9967\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 234s 4ms/sample - loss: 0.0142 - accuracy: 0.9973\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 233s 4ms/sample - loss: 0.0111 - accuracy: 0.9979\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 235s 4ms/sample - loss: 0.0104 - accuracy: 0.9976\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 236s 4ms/sample - loss: 0.0113 - accuracy: 0.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dedcf6f940>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 32, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 399us/sample - loss: 0.0377 - accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03769001886101469, 0.9922]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"mnist_weigths.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(inputs = base_model.input, outputs = predictions)\n",
    "model2.compile(optimizer='Adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para cargar los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights(\"mnist_weigths.hdf5\", by_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 401us/sample - loss: 0.0377 - accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03769001886101469, 0.9922]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test, y_test, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas en affnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n",
      "test_set (1600, 10000)\n",
      "label_set (10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)\n",
    "\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "def visualization(x, y,count,index):\n",
    "    x = np.reshape(x, (40, 40))\n",
    "    \n",
    "    plt.subplot(1,count,index)\n",
    "    plt.imshow(x, cmap=cm.Greys_r)\n",
    "    plt.title(y)\n",
    "    plt.axis('off')   \n",
    "\n",
    "def visualization_overlap(x0,x1, y0,y1,count,index):\n",
    "    r = np.reshape(x0, (40, 40))\n",
    "    g = np.reshape(x1, (40, 40))\n",
    "    b = np.zeros_like(r)\n",
    "    rgb = np.stack([r,g,b],-1)\n",
    "    \n",
    "    plt.subplot(1,count,index)\n",
    "    plt.imshow(rgb)\n",
    "    plt.title('R:('+ str(y0)+','+str(y1)+')')\n",
    "    plt.axis('off')   \n",
    "\n",
    "def load_test_affNIST():\n",
    "    path = 'test_affnist/test_batches/1.mat'\n",
    "    dataset = loadmat(path)\n",
    "\n",
    "    ans_set = dataset['affNISTdata']['label_int']\n",
    "    test_set = dataset['affNISTdata']['image']\n",
    "    for i in test_set[:100]:\n",
    "         print (i)\n",
    "    print ('test_set',test_set.shape)# (10000, 1600)\n",
    "    print ('label_set',ans_set.shape)#(10000,)\n",
    "    return test_set,ans_set\n",
    "\n",
    "def load_train_affNIST():\n",
    "    path = 'data/affNIST/train/1.mat'\n",
    "    dataset = loadmat(path)\n",
    "\n",
    "    ans_set = dataset['affNISTdata']['label_int']\n",
    "    train_set = dataset['affNISTdata']['image']\n",
    "    for i in train_set[:100]:\n",
    "         print (i)\n",
    "    print ('train_set',train_set.shape)# (60000, 1600)\n",
    "    print ('label_set',ans_set.shape)#(60000,)\n",
    "    return train_set,ans_set\n",
    "\n",
    "\n",
    "def write_labeldata(labeldata, outputfile):\n",
    "  header = np.array([0x0801, len(labeldata)], dtype='>i4')\n",
    "  with open(outputfile, \"wb\") as f:\n",
    "    f.write(header.tobytes())\n",
    "    f.write(labeldata.tobytes())\n",
    "\n",
    "def write_imagedata(imagedata, outputfile):\n",
    "  header = np.array([0x0803, len(imagedata), 28, 28], dtype='>i4')\n",
    "  with open(outputfile, \"wb\") as f:\n",
    "    f.write(header.tobytes())\n",
    "    f.write(imagedata.tobytes())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    OVERLAP = not True\n",
    "    count = 10\n",
    "\n",
    "    test_set,ans_set = load_test_affNIST()\n",
    "    #print ('min',np.min(test_set[0]),np.max(test_set[0]))\n",
    "    #write_labeldata(ans_set,\"test_affnist/test_batches/t10k-labels-idx1-ubyte\")\n",
    "    #write_imagedata(test_set,\"test_affnist/test_batches/t10k-images-idx3-ubyte\")\n",
    "\n",
    "    #train_set,ans_set = load_train_affNIST()\n",
    "    #print ('min',np.min(train_set[0]),np.max(train_set[0]))\n",
    "    #write_labeldata(ans_set,\"data/affNIST/train/train-labels-idx1-ubyte\")\n",
    "    #write_imagedata(train_set,\"data/affNIST/train/train-images-idx3-ubyte\")\n",
    "    # train_set_overlap = train_set[0::2]+train_set[1::2]    \n",
    "    # for j in range((int)(len(ans_set)/count)):\n",
    "    #     for i in range(count):\n",
    "    #         index = np.minimum(j*count+i, len(ans_set)-1)\n",
    "    #         if OVERLAP:\n",
    "    #             visualization_overlap(train_set[index],train_set[index+1],ans_set[index],ans_set[index+1],count,i+1)\n",
    "    #         else: \n",
    "    #             visualization(train_set[index], ans_set[index],count,i+1)\n",
    "\n",
    "    #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = test_set.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 = np.resize(tt,(10000,40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2 = tt2[...,tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt3 = tf.image.resize(tt2, size=[32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt4 = tt3.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 174us/sample - loss: 4.1773 - accuracy: 0.2616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.177292580413819, 0.2616]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(tt4, ans_set, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
